{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a 'Bunch' of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2257 datasets with 4 targets:\n",
      " ['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n"
     ]
    }
   ],
   "source": [
    "## Only examine 4 of the total 20 categories\n",
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "# twenty_train = fetch_20newsgroups(subset='train',categories=categories, shuffle=True, random_state=42)\n",
    "# with open ('/Users/zachdischner/Desktop/twentytrain.pkl','wb') as pfile:\n",
    "#     pickle.dump(twenty_train,pfile)\n",
    "with open(\"/Users/zachdischner/Desktop/twentytrain.pkl\",'rb') as pfile:\n",
    "    twenty_train=pickle.load(pfile)\n",
    "print(\"{} datasets with {} targets:\\n {}\".format(len(twenty_train.data),len(twenty_train.target_names),twenty_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 email Category Names\n",
      "\ttarget 1 ==> comp.graphics\n",
      "\ttarget 1 ==> comp.graphics\n",
      "\ttarget 3 ==> soc.religion.christian\n",
      "\ttarget 3 ==> soc.religion.christian\n",
      "\ttarget 3 ==> soc.religion.christian\n",
      "\ttarget 3 ==> soc.religion.christian\n",
      "\ttarget 3 ==> soc.religion.christian\n",
      "\ttarget 2 ==> sci.med\n",
      "\ttarget 2 ==> sci.med\n",
      "\ttarget 2 ==> sci.med\n"
     ]
    }
   ],
   "source": [
    "## print an email: twenty_train.data[100]\n",
    "## See what it's target (answer): twenty_train.target[100]\n",
    "## See it's ascii name: twenty_train.target_names[twenty_train.target[100]]\n",
    "print(\"First 10 email Category Names\")\n",
    "for t in twenty_train.target[:10]:\n",
    "    print(\"\\ttarget {} ==> {}\".format(t,twenty_train.target_names[t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokenizing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape\n",
    "## count_vect['word'] ==> Number of times word has occured in training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting counts to frequencies\n",
    "* Normalize counts per document by total number of words in a document\n",
    "* Downscale weights of words that occur across many documents, AKA common ones\n",
    "* Called `tf-idf`: \"Term Frequence time Inverse Document Frequency\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Naive Bayes classifier (multinominal variant) is a good one for word counts evidently\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf,twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "God is love ==> soc.religion.christian\n",
      "OpenGL on the GPU is fast ==> comp.graphics\n"
     ]
    }
   ],
   "source": [
    "## Test out some new documents\n",
    "docs_new = ['God is love','OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "for doc,category in zip(docs_new,predicted):\n",
    "    print(\"{} ==> {}\".format(doc,twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline!\n",
    "This is putting it all together so we can simplify the\n",
    "    text ==> vectorizer ==> transformer ==> classifier\n",
    "workflow easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a single pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf = text_clf.fit(twenty_train.data,twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out new data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text classifier accuracy on test set  is %83.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test',categories=categories, shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "accuracy = np.mean(predicted == twenty_test.target)\n",
    "print(\"Text classifier accuracy on test set  is %{:3.3}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*83%* kinda sucks. But SVGs are normally really good at text classifiers!\n",
    "* Plug in an SGD Classifier into our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD accuracy is %91.3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                          alpha=1e-3, n_iter=5,\n",
    "                                         random_state=42))\n",
    "                    ])\n",
    "\n",
    "## Train\n",
    "_ = sgd_clf.fit(twenty_train.data, twenty_train.target)\n",
    "predicted = sgd_clf.predict(docs_test)\n",
    "\n",
    "## How did we do?\n",
    "accuracy = np.mean(predicted==twenty_test.target)\n",
    "print(\"SGD accuracy is %{:3.3}\".format(accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.81      0.87       319\n",
      "         comp.graphics       0.88      0.97      0.92       389\n",
      "               sci.med       0.94      0.90      0.92       396\n",
      "soc.religion.christian       0.90      0.95      0.93       398\n",
      "\n",
      "           avg / total       0.92      0.91      0.91      1502\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[258,  11,  15,  35],\n",
       "       [  4, 379,   3,   3],\n",
       "       [  5,  33, 355,   3],\n",
       "       [  5,  10,   4, 379]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names))\n",
    "\n",
    "### Confusion matrix (whatever that is...)\n",
    "metrics.confusion_matrix(twenty_test.target, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning Using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Instead of blindly checking and tuning by hand, we'll look at *all* parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range':[(1,1),(1,2)],\n",
    "              'tfidf__use_idf':(True,False),\n",
    "              'clf__alpha':(1e-2,1e-3,1e-4,1e-5),\n",
    "             }\n",
    "\n",
    "## let the program determine how many cores we have available, n_jobs=-1\n",
    "gs_clf = GridSearchCV(sgd_clf, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Result of grid search is a normal sklearn model. Let's try it out! \n",
    "gs_clf = gs_clf.fit(twenty_train.data[:400], twenty_train.target[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soc.religion.christian\n",
      "comp.graphics\n"
     ]
    }
   ],
   "source": [
    "## See some results\n",
    "print(twenty_train.target_names[gs_clf.predict(['God is love'])[0]])\n",
    "print(twenty_train.target_names[gs_clf.predict(['God is love but graphics on GPUs run much faster on multi cores'])[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "gs_clf.best_score_\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"{}: {}\".format(param_name,gs_clf.best_params_[param_name]))\n",
    "\n",
    "## More detailed summary\n",
    "# gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
